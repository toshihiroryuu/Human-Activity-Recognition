{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL : https://github.com/nxs5899/end-to-end-Machine-Learning-model-with-MLlib-in-pySpark/blob/master/MLlib_pySpark.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL : https://towardsdatascience.com/build-an-end-to-end-machine-learning-model-with-mllib-in-pyspark-4917bdf289c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "       .master(\"local\") \\\n",
<<<<<<< HEAD
    "       .appName(\"Athulspark\") \\\n",
=======
    "       .appName(\"HARspark\") \\\n",
>>>>>>> e2d5bc2532329a157f5a15df4f5d175f60e2345b
    "       .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- rotationRate: double (nullable = true)\n",
      " |-- userAcceleration: double (nullable = true)\n",
      " |-- act: double (nullable = true)\n",
      " |-- id: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- height: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: double (nullable = true)\n",
      " |-- trial: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "new_df = spark.read.csv('athul_test.csv', header=True, inferSchema=True)\n",
=======
    "new_df = spark.read.csv('test.csv', header=True, inferSchema=True)\n",
>>>>>>> e2d5bc2532329a157f5a15df4f5d175f60e2345b
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_lbl = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>234657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>224816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>158645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>58204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>104327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   count\n",
       "0    0.0  234657\n",
       "1    1.0  224816\n",
       "2    4.0  158645\n",
       "3    3.0   58204\n",
       "4    2.0   50246\n",
       "5    5.0  104327"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col = ['_c0', 'id', 'trial']\n",
    "\n",
    "new_df = new_df.select([column for column in new_df.columns if column not in drop_col])\n",
    "new_df = new_df.withColumnRenamed('act', 'label')\n",
    "new_df.groupby('label').count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn\n",
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sparkenv\\opt\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\conversion.py:87: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 1.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830895\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline\n",
    "\n",
    "df_pd = new_df.toPandas()\n",
    "print(len(df_pd))\n",
    "\n",
    "# plt.figure(figsize=(12,10))\n",
    "# sns.countplot(x='label', data=df_pd, order=df_pd['label'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotationRate</th>\n",
       "      <th>userAcceleration</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.014892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008544</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rotationRate  userAcceleration  label  weight  height   age  gender\n",
       "0      0.010253          0.006959    0.0   102.0   188.0  46.0     1.0\n",
       "1      0.010920          0.010673    0.0   102.0   188.0  46.0     1.0\n",
       "2      0.008377          0.007010    0.0   102.0   188.0  46.0     1.0\n",
       "3      0.006555          0.014892    0.0   102.0   188.0  46.0     1.0\n",
       "4      0.007724          0.013001    0.0   102.0   188.0  46.0     1.0\n",
       "5      0.008544          0.008358    0.0   102.0   188.0  46.0     1.0\n",
       "6      0.010706          0.007313    0.0   102.0   188.0  46.0     1.0\n",
       "7      0.006017          0.011407    0.0   102.0   188.0  46.0     1.0\n",
       "8      0.010136          0.008716    0.0   102.0   188.0  46.0     1.0\n",
       "9      0.011316          0.010180    0.0   102.0   188.0  46.0     1.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(new_df.take(10), columns= new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  categorical features\n",
      "6  numerical features\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [item[0] for item in new_df.dtypes if item[1].startswith('string')] \n",
    "print(str(len(cat_cols)) + '  categorical features')\n",
    "\n",
    "num_cols = [item[0] for item in new_df.dtypes if item[1].startswith('int') | item[1].startswith('double')][1:]\n",
    "print(str(len(num_cols)) + '  numerical features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_missing_table(df_pd):\n",
    "    \"\"\"Input pandas dataframe and Return columns with missing value and percentage\"\"\"\n",
    "    mis_val = df_pd.isnull().sum() #count total of null in each columns in dataframe\n",
    "#count percentage of null in each columns\n",
    "    mis_val_percent = 100 * df_pd.isnull().sum() / len(df_pd) \n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) \n",
    " #join to left (as column) between mis_val and mis_val_percent\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'}) \n",
    "#rename columns in table\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "    mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1) \n",
    "        \n",
    "    print (\"Your selected dataframe has \" + str(df_pd.shape[1]) + \" columns.\\n\"    #.shape[1] : just view total columns in dataframe  \n",
    "    \"There are \" + str(mis_val_table_ren_columns.shape[0]) +              \n",
    "    \" columns that have missing values.\") #.shape[0] : just view total rows in dataframe\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 7 columns.\n",
      "There are 0 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Values, % of Total Values]\n",
       "Index: []"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missings = info_missing_table(df_pd)\n",
    "missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missings(spark_df):\n",
    "    null_counts = []        \n",
    "    for col in spark_df.dtypes:    \n",
    "        cname = col[0]     \n",
    "        ctype = col[1]      \n",
    "        nulls = spark_df.where( spark_df[cname].isNull()).count() #check count of null in column name\n",
    "        result = tuple([cname, nulls])  #new tuple, (column name, null count)\n",
    "        null_counts.append(result)      #put the new tuple in our result list\n",
    "    null_counts=[(x,y) for (x,y) in null_counts if y!=0]  #view just columns that have missing values\n",
    "    return null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_counts = count_missings(new_df)\n",
    "miss_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adding the new column weights and fill it with ratios\n",
    "# from pyspark.sql.functions import when\n",
    "\n",
    "# ratio = 0.91\n",
    "# def weight_balance(labels):\n",
    "#     return when(labels == 1, ratio).otherwise(1*(1-ratio))\n",
    "\n",
    "# new_df = new_df.withColumn('weights', weight_balance(col('label')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotationRate</th>\n",
       "      <th>userAcceleration</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.014892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008544</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rotationRate  userAcceleration  label  weight  height   age  gender\n",
       "0      0.010253          0.006959    0.0   102.0   188.0  46.0     1.0\n",
       "1      0.010920          0.010673    0.0   102.0   188.0  46.0     1.0\n",
       "2      0.008377          0.007010    0.0   102.0   188.0  46.0     1.0\n",
       "3      0.006555          0.014892    0.0   102.0   188.0  46.0     1.0\n",
       "4      0.007724          0.013001    0.0   102.0   188.0  46.0     1.0\n",
       "5      0.008544          0.008358    0.0   102.0   188.0  46.0     1.0\n",
       "6      0.010706          0.007313    0.0   102.0   188.0  46.0     1.0\n",
       "7      0.006017          0.011407    0.0   102.0   188.0  46.0     1.0\n",
       "8      0.010136          0.008716    0.0   102.0   188.0  46.0     1.0\n",
       "9      0.011316          0.010180    0.0   102.0   188.0  46.0     1.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_df.take(10), columns= new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "stages = []\n",
    "for categoricalCol in cat_cols:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "\n",
    "assemblerInputs = [c + \"classVec\" for c in cat_cols] + num_cols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cols = new_df.columns\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(new_df)\n",
    "new_df = pipelineModel.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>rotationRate</th>\n",
       "      <th>userAcceleration</th>\n",
       "      <th>label</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.006959199379238966, 0.0, 102.0, 188.0, 46.0...</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.010672920359489243, 0.0, 102.0, 188.0, 46.0...</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0070096587648757905, 0.0, 102.0, 188.0, 46....</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.014892331247994722, 0.0, 102.0, 188.0, 46.0...</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.014892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.013001225519157802, 0.0, 102.0, 188.0, 46.0...</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  rotationRate  \\\n",
       "0  [0.006959199379238966, 0.0, 102.0, 188.0, 46.0...      0.010253   \n",
       "1  [0.010672920359489243, 0.0, 102.0, 188.0, 46.0...      0.010920   \n",
       "2  [0.0070096587648757905, 0.0, 102.0, 188.0, 46....      0.008377   \n",
       "3  [0.014892331247994722, 0.0, 102.0, 188.0, 46.0...      0.006555   \n",
       "4  [0.013001225519157802, 0.0, 102.0, 188.0, 46.0...      0.007724   \n",
       "\n",
       "   userAcceleration  label  weight  height   age  gender  \n",
       "0          0.006959    0.0   102.0   188.0  46.0     1.0  \n",
       "1          0.010673    0.0   102.0   188.0  46.0     1.0  \n",
       "2          0.007010    0.0   102.0   188.0  46.0     1.0  \n",
       "3          0.014892    0.0   102.0   188.0  46.0     1.0  \n",
       "4          0.013001    0.0   102.0   188.0  46.0     1.0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedCols = ['features']+cols\n",
    "new_df = new_df.select(selectedCols)\n",
    "pd.DataFrame(new_df.take(5), columns=new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664598\n",
      "166297\n"
     ]
    }
   ],
   "source": [
    "# split the data into trainign and testin sets\n",
    "\n",
    "train, test = new_df.randomSplit([0.80, 0.20], seed = 42)\n",
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we check how LogisticRegression perform \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=15)\n",
    "LR_model = LR.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label')\n",
    "DT_model = dt.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Train a RandomForestClassifier model.\n",
    "rf = RandomForestClassifier(numTrees=3, maxDepth=2, labelCol=\"label\", seed=42)\n",
    "RF_model = rf.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "# Train a NaiveBayes model.\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "NB_model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputCols = [\"rotationRate\", \"userAcceleration\",\"weight\", \"height\", \"age\", \"gender\"]\n",
    "\n",
    "outputCol = \"features\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = spark.createDataFrame([(3.8651705114155055,1.6289638410434408,70.0,180.0,35.0,1.0)], inputCols)\n",
    "df_va = VectorAssembler(inputCols = inputCols, outputCol = outputCol)\n",
    "\n",
    "df = df_va.transform(df)\n",
    "\n",
    "prediction = LR_model.transform(df)\n",
    "prediction.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(prediction)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "\n",
    "# Convert the Spark DataFrame back to a pandas DataFrame using Arrow\n",
    "result_pdf = prediction.select(\"*\").toPandas()\n",
    "result_pdf.prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selector(algo):\n",
    "    model = LR_model\n",
    "    if algo == \"Logistic regression\":\n",
    "        model = LR_model\n",
    "    elif algo == \"Decision Tree\":\n",
    "        model = DT_model\n",
    "    elif algo == \"Naive Bayes\":\n",
    "        model = NB_model\n",
    "    elif algo == \"Random Forest\":\n",
    "        model = RF_model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'870933.79129_3_5.178_-10.028_8.125'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = urllib.request.urlopen('https://api.thingspeak.com/channels/508740/fields/1/last.json').read()\n",
    "res_dict = json.loads(b.decode('utf-8'))\n",
    "res_dict['field1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1456105.52575_3_-1.260_0.235_9.813'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = urllib.request.urlopen('https://api.thingspeak.com/channels/508740/fields/2/last.json').read()\n",
    "res_dict = json.loads(a.decode('utf-8'))\n",
    "res_dict['field2']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"https://api.thingspeak.com/channels/508740/fields/1.json?results=2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_mobile1():\n",
    "    a = urllib.request.urlopen('https://api.thingspeak.com/channels/508740/fields/1/last.json').read()\n",
    "    res_dict = json.loads(a.decode('utf-8'))\n",
    "    \n",
    "    mobile1_values = res_dict['field1']\n",
    "    x = list(map(float, mobile1_values.split('_')))\n",
    "    \n",
    "    sqrt_acceler  = 0\n",
    "    sqrt_gyro = 0\n",
    "    i = 0\n",
    "    for item in x:  \n",
    "        i = i+1\n",
    "        if item == 3.0:\n",
    "            acceleros=[x[i],x[i+1],x[i+2]]\n",
    "            sqrt_acceler = np.sqrt(sum(j*j for j in acceleros))\n",
    "#             print(sqrt_acceler)\n",
    "\n",
    "        if item == 4.0:\n",
    "            gyros=[x[i],x[i+1],x[i+2]]\n",
    "            sqrt_gyro = np.sqrt(sum(j*j for j in gyros))\n",
    "#             print(sqrt_gyro)\n",
    "            \n",
    "    return float(sqrt_acceler), float(sqrt_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_mobile2():\n",
    "    a = urllib.request.urlopen('https://api.thingspeak.com/channels/508740/fields/2/last.json').read()\n",
    "    res_dict = json.loads(a.decode('utf-8'))\n",
    "\n",
    "    mobile2_values = res_dict[\"field2\"]\n",
    "    x = list(map(float, mobile2_values.split('_')))\n",
    "    i = 0\n",
    "\n",
    "    sqrt_acceler  = 0\n",
    "    sqrt_gyro = 0\n",
    "    for item in x:\n",
    "        i = i+1\n",
    "        if item == 3.0:\n",
    "            acceleros=[x[i],x[i+1],x[i+2]]\n",
    "            sqrt_acceler = np.sqrt(sum(j*j for j in acceleros))\n",
    "#             print(sqrt_acceler)\n",
    "\n",
    "        if item == 4.0:\n",
    "            gyros=[x[i],x[i+1],x[i+2]]\n",
    "            sqrt_gyro = np.sqrt(sum(j*j for j in gyros))\n",
    "#             print(sqrt_gyro)\n",
    "\n",
    "    return float(sqrt_acceler), float(sqrt_gyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.9064047474536, 0.0)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_mobile1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.896352560413357, 0.0)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_mobile2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(device):\n",
    "    acc1 = 0\n",
    "    gyro1 = 0\n",
    "    acc2 = 0\n",
    "    gyro2 = 0\n",
    "    \n",
    "    if device == \"Device 1\":\n",
    "        acc1, gyro1  = get_data_mobile1() \n",
    "    elif device == \"Device 2\":\n",
    "        acc2, gyro2  = get_data_mobile2() \n",
    "    else:\n",
    "        acc1, gyro1  = get_data_mobile1()\n",
    "        acc2, gyro2  = get_data_mobile2() \n",
    "        \n",
    "    return gyro1, acc1, gyro2, acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_lbl = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying', 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(device, algo, gender, age, height, weight):\n",
    "    \n",
    "    if gender ==  \"Male\":\n",
    "        gender = 0\n",
    "    else:\n",
    "        gender = 1\n",
    "        \n",
    "    print(device, algo, gender, age, height, weight)\n",
    "    \n",
    "    prediction1 = 6\n",
    "    prediction2 = 6\n",
    "    acc1, gyro1 = 0, 0\n",
    "    acc2, gyro2 = 0, 0\n",
    "    \n",
    "    if device == \"Device 1\":\n",
    "        print(\"Device 1 Selected\")\n",
    "        gyro, acc, _ , _ = get_input(device)\n",
    "        df = spark.createDataFrame([(gyro,acc,weight, height, age, gender)], inputCols)\n",
    "        df_va = VectorAssembler(inputCols = inputCols, outputCol = outputCol)\n",
    "        df = df_va.transform(df)\n",
    "        model = model_selector(algo)\n",
    "        prediction = model.transform(df)\n",
    "        result_pdf = prediction.select(\"*\").toPandas()\n",
    "        prediction1 = result_pdf.prediction[0]\n",
    "        print(gyro1, acc1)\n",
    "        \n",
    "    elif device == \"Device 2\":\n",
    "        print(\"Device 2 Selected\")\n",
    "        _ , _ , gyro, acc = get_input(device)\n",
    "        df = spark.createDataFrame([(gyro,acc,weight, height, age, gender)], inputCols)\n",
    "        df_va = VectorAssembler(inputCols = inputCols, outputCol = outputCol)\n",
    "        df = df_va.transform(df)\n",
    "        model = model_selector(algo)\n",
    "        prediction = model.transform(df)\n",
    "        result_pdf = prediction.select(\"*\").toPandas()\n",
    "        prediction2 = result_pdf.prediction[0]\n",
    "        print(gyro2, acc2)\n",
    "        \n",
    "    else:\n",
    "        print(\"Device 1 & 2\")\n",
    "        gyro1, acc1, gyro2, acc2 = get_input(device)\n",
    "        \n",
    "        df = spark.createDataFrame([(gyro1, acc1, weight, height, age, gender)], inputCols)\n",
    "        df_va = VectorAssembler(inputCols = inputCols, outputCol = outputCol)\n",
    "        df = df_va.transform(df)\n",
    "        model = model_selector(algo)\n",
    "        prediction = model.transform(df)\n",
    "        result_pdf = prediction.select(\"*\").toPandas()\n",
    "        prediction1 = result_pdf.prediction[0]\n",
    "        print(gyro1, acc1)\n",
    "        \n",
    "        df = spark.createDataFrame([(gyro2,acc2,weight, height, age, gender)], inputCols)\n",
    "        df_va = VectorAssembler(inputCols = inputCols, outputCol = outputCol)\n",
    "        df = df_va.transform(df)\n",
    "        model = model_selector(algo)\n",
    "        prediction = model.transform(df)\n",
    "        result_pdf = prediction.select(\"*\").toPandas()\n",
    "        prediction2 = result_pdf.prediction[0]\n",
    "        print(gyro2, acc2)\n",
    "        \n",
    "\n",
    "    return acc1, gyro1, act_lbl[int(prediction1)], acc2, gyro2, act_lbl[int(prediction2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally at: http://127.0.0.1:7877/\n",
      "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
      "Running on External URL: https://37226.gradio.app\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"https://37226.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11d66a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7877/',\n",
       " 'https://37226.gradio.app')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sparkenv\\opt\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\pandas\\conversion.py:87: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 1.0.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0.0 14.232144954292728\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0.0 13.435217713159695\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0.0 13.435217713159695\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0.0 17.570527994343255\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 17.570527994343255\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 14.920498952783047\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.896352560413357\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.947270329090287\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.948462242980067\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.951145913913633\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.951145913913633\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.942281478614452\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.966572530213183\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.97596416392922\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.892240443903495\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.688979616038006\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.896352560413357\n",
      "Device 1 & 2 Logistic Regression 1 25 180 74\n",
      "Device 1 & 2\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0.0 9.688979616038006\n",
      "0.0 9.86408297815869\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n",
      "0 0\n",
      "Device 1 Logistic Regression 1 25 180 74\n",
      "Device 1 Selected\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "img = gr.inputs.Image()\n",
    "\n",
    "title = \"Human Activity Recognition\"\n",
    "\n",
    "device = gr.inputs.Dropdown(choices = [\"Device 1\", \"Device 2\", \"Device 1 & 2\"], type=\"value\", label=\"Select Device\")\n",
    "\n",
    "algo = gr.inputs.Radio([\"Logistic Regression\", \"Decision Tree\", \"Naive Bayes\", \"Random Forest\"], label=\"Choose Algorithm\")\n",
    "\n",
    "gender = gr.inputs.CheckboxGroup(choices = [\"Male\", \"Female\"], type=\"value\", label=\"Gender\")\n",
    "age = gr.inputs.Slider(minimum = 20, maximum=80, step=1, default=25, label=\"Age\")\n",
    "height = gr.inputs.Slider(minimum = 100, maximum=200, step=1, default=180, label=\"Height\")\n",
    "weight = gr.inputs.Slider(minimum = 40, maximum=90, step=1, default=74, label=\"Weight\")\n",
    "\n",
    "acc1 = gr.outputs.Textbox(type=\"auto\", label=\"Accelerometer - Device-1 \")\n",
    "gyro1 = gr.outputs.Textbox(type=\"auto\", label=\"Gyroscope - Device-1\")\n",
    "prediction1 = gr.outputs.Textbox(type=\"auto\", label=\"Device 1\")\n",
    "\n",
    "acc2 = gr.outputs.Textbox(type=\"auto\", label=\"Accelerometer - Device-2 \")\n",
    "gyro2 = gr.outputs.Textbox(type=\"auto\", label=\"Gyroscope - Device-2\")\n",
    "prediction2 = gr.outputs.Textbox(type=\"auto\", label=\"Device 2\")\n",
    "\n",
    "gr.Interface(get_prediction, inputs = [device, algo, gender, age, height, weight],   \n",
    "             outputs = [acc1, gyro1, prediction1, acc2, gyro2,prediction2], \n",
    "             title=title,\n",
    "             live=True).launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.8.3"
=======
   "version": "3.8.8"
>>>>>>> e2d5bc2532329a157f5a15df4f5d175f60e2345b
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
